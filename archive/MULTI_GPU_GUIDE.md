# FDA-MIMO CVNN å¤šGPUè®­ç»ƒæŒ‡å— (6x 2080Ti æœåŠ¡å™¨)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ä¸Šä¼ ä»£ç åˆ°æœåŠ¡å™¨
```bash
# åœ¨æœ¬åœ°æ‰“åŒ…
tar -czf CVNN-FDA.tar.gz CVNN-FDA/

# ä¸Šä¼ åˆ°æœåŠ¡å™¨
scp CVNN-FDA.tar.gz user@server:/path/to/workspace/

# åœ¨æœåŠ¡å™¨ä¸Šè§£å‹
ssh user@server
cd /path/to/workspace/
tar -xzf CVNN-FDA.tar.gz
cd CVNN-FDA
```

### 2. æ£€æŸ¥GPUçŠ¶æ€
```bash
nvidia-smi
# ç¡®è®¤6å¼ 2080Tiéƒ½åœ¨çº¿
```

### 3. å®‰è£…ä¾èµ–
```bash
pip install torch torchvision numpy matplotlib tqdm
```

### 4. å¼€å§‹è®­ç»ƒ

#### æ–¹æ¡ˆA: Proæ¨¡å‹ (æ¨è) - 6å¡å…¨å¼€
```bash
chmod +x train_multi_gpu.sh
nohup bash train_multi_gpu.sh > training.log 2>&1 &
```

#### æ–¹æ¡ˆB: Standardæ¨¡å‹ (æ›´å¿«) - 3å¡
```bash
chmod +x train_standard.sh
nohup bash train_standard.sh > training_std.log 2>&1 &
```

#### æ–¹æ¡ˆC: è‡ªå®šä¹‰è®­ç»ƒ
```bash
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5

python main.py \
    --mode train \
    --model pro \
    --epochs 100 \
    --batch_size 192 \
    --lr 5e-5 \
    --train_size 30000 \
    --num_workers 16 \
    --multi_gpu
```

## ğŸ“Š æ€§èƒ½é¢„æœŸ

### Proæ¨¡å‹ (19Må‚æ•°)
- **æ€»Batch Size**: 192 (32 per GPU Ã— 6)
- **è®­ç»ƒæ—¶é—´**: ~2-3å°æ—¶ (100 epochs)
- **ç›®æ ‡æ€§èƒ½**:
  - SNR=10dB: RMSE_r < 5m, RMSE_Î¸ < 0.5Â°
  - SNR=0dB: RMSE_r < 10m, RMSE_Î¸ < 1.0Â°

### Standardæ¨¡å‹ (6Må‚æ•°)
- **æ€»Batch Size**: 96 (32 per GPU Ã— 3)
- **è®­ç»ƒæ—¶é—´**: ~1-2å°æ—¶ (80 epochs)
- **ç›®æ ‡æ€§èƒ½**:
  - SNR=10dB: RMSE_r < 8m, RMSE_Î¸ < 0.8Â°

## ğŸ”§ é…ç½®è¯´æ˜

### æ‰¹å¤§å°è®¡ç®—
- **å•GPUæœ€å¤§**: 32 (2080Ti 11GBæ˜¾å­˜)
- **6å¡æ€»æ‰¹å¤§å°**: 192
- **3å¡æ€»æ‰¹å¤§å°**: 96

### Workeræ•°é‡
- **æ¨è**: 2-3 Ã— GPUæ•°é‡
- **6å¡**: 16-18 workers
- **3å¡**: 8-12 workers

### å­¦ä¹ ç‡è°ƒæ•´
- **å¤šGPUåŠ é€Ÿ**: batch sizeè¶Šå¤§ï¼Œå­¦ä¹ ç‡å¯ç•¥å¾®æé«˜
- **æ¨è**: 5e-5 (ç¨³å®š) æˆ– 1e-4 (å¿«é€Ÿ)

## ğŸ“ ç›‘æ§è®­ç»ƒ

### å®æ—¶æŸ¥çœ‹æ—¥å¿—
```bash
tail -f training.log
```

### æ£€æŸ¥GPUä½¿ç”¨ç‡
```bash
watch -n 1 nvidia-smi
```

### æŸ¥çœ‹è®­ç»ƒå†å²
```bash
python -c "import json; print(json.load(open('results/training_history.json')))"
```

## ğŸ¯ è®­ç»ƒå®Œæˆå

### 1. æŸ¥çœ‹ç»“æœ
```bash
ls checkpoints/  # æ¨¡å‹æ–‡ä»¶
ls results/      # å›¾è¡¨å’ŒæŠ¥å‘Š
cat results/evaluation_results.txt
```

### 2. ä¸‹è½½ç»“æœåˆ°æœ¬åœ°
```bash
# åœ¨æœ¬åœ°æ‰§è¡Œ
scp -r user@server:/path/to/workspace/CVNN-FDA/checkpoints ./
scp -r user@server:/path/to/workspace/CVNN-FDA/results ./
```

### 3. å¯è§†åŒ–
æ‰“å¼€ `results/` ç›®å½•ä¸‹çš„PNGå›¾ç‰‡ï¼š
- `training_history.png` - è®­ç»ƒæ›²çº¿
- `rmse_vs_snr.png` - æ€§èƒ½æ›²çº¿
- `scatter_comparison.png` - é¢„æµ‹å¯¹æ¯”
- `error_distribution.png` - è¯¯å·®åˆ†å¸ƒ

## âœ… æ€§èƒ½ä¼˜åŒ– (CPUå ç”¨100% â†’ 20%)

**é—®é¢˜**: åŠ¨æ€æ•°æ®ç”Ÿæˆå¯¼è‡´CPUæ»¡è½½ï¼ŒGPUç­‰å¾…æ•°æ®
**è§£å†³**: ä½¿ç”¨ `--use_cache` é¢„ç”Ÿæˆæ•°æ®åˆ°å†…å­˜

| æ¨¡å¼ | CPUå ç”¨ | GPUåˆ©ç”¨ç‡ | å¯åŠ¨æ—¶é—´ | å†…å­˜å ç”¨ | è®­ç»ƒé€Ÿåº¦ |
|------|---------|-----------|----------|----------|----------|
| åŠ¨æ€ç”Ÿæˆ | ~100% | 60-70% | ç«‹å³ | ~2GB | åŸºå‡† |
| **ç¼“å­˜æ¨¡å¼** | **20-30%** | **85-95%** | +1-2åˆ†é’Ÿ | ~6GB | **+30-50%** |

**æ¨èé…ç½®**:
```bash
# ç¼“å­˜æ¨¡å¼ (æ¨è)
python main.py --use_cache --num_workers 4

# åŠ¨æ€æ¨¡å¼ (å†…å­˜å—é™æ—¶)
python main.py --num_workers 16
```

**å¯¹æ¯”æµ‹è¯•**:
```bash
bash benchmark_cpu.sh  # è¿è¡ŒCPUå ç”¨å¯¹æ¯”
```

## âœ… DataParallel å…¼å®¹æ€§ä¿®å¤

æœ¬å®ç°å·²ä¿®å¤PyTorch DataParallelå¯¹å¤æ•°å¼ é‡çš„å…¼å®¹æ€§é—®é¢˜ï¼š

**ä¿®å¤æ–¹æ¡ˆ**:
- Datasetè¿”å›2é€šé“å®æ•°å¼ é‡ `[real, imag]` è€ŒéåŸç”Ÿå¤æ•°
- æ¨¡å‹forwardå…¥å£è‡ªåŠ¨è½¬æ¢ä¸ºå¤æ•°å¼ é‡
- æ‰€æœ‰ä¸­é—´å±‚æ­£å¸¸ä½¿ç”¨å¤æ•°è¿ç®—

**æµ‹è¯•**:
```bash
python test_multi_gpu.py  # éªŒè¯å¤šGPUå…¼å®¹æ€§
```

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ˜¾å­˜ä¸è¶³ (CUDA out of memory)
**è§£å†³**: å‡å°batch_size
```bash
python main.py --batch_size 96  # ä»192é™åˆ°96
```

### Q2: åªæƒ³ç”¨éƒ¨åˆ†GPU
**è§£å†³**: è®¾ç½®CUDA_VISIBLE_DEVICES
```bash
export CUDA_VISIBLE_DEVICES=0,1,2  # åªç”¨å‰3å¼ å¡
```

### Q3: è®­ç»ƒé€Ÿåº¦æ…¢
**æ£€æŸ¥**:
- `num_workers` æ˜¯å¦è®¾ç½® (æ¨è12-16)
- æ•°æ®æ˜¯å¦åœ¨SSDä¸Š
- GPUåˆ©ç”¨ç‡æ˜¯å¦æ¥è¿‘100%

### Q4: ä¸­æ–­åæ¢å¤è®­ç»ƒ
ä»£ç ä¼šè‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œä½†ç›®å‰ä¸æ”¯æŒè‡ªåŠ¨æ¢å¤ã€‚
å¯ä»¥é€šè¿‡ä¿®æ”¹ä»£ç æ·»åŠ  `--resume` é€‰é¡¹ã€‚

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®é¢„åŠ è½½
å¦‚æœç£ç›˜I/Oæ˜¯ç“¶é¢ˆï¼Œå¯ä»¥å°†æ•°æ®é¢„ç”Ÿæˆåˆ°å†…å­˜:
```python
# ä¿®æ”¹dataset.pyï¼Œæ·»åŠ æ•°æ®ç¼“å­˜
```

### 2. æ··åˆç²¾åº¦è®­ç»ƒ
å¯ä»¥è¿›ä¸€æ­¥åŠ é€Ÿï¼ˆä½†PyTorchå¤æ•°è¿ç®—å¯¹AMPæ”¯æŒæœ‰é™ï¼‰

### 3. å­¦ä¹ ç‡è°ƒåº¦
å½“å‰ä½¿ç”¨ReduceLROnPlateauï¼Œå¯ä»¥å°è¯•:
- CosineAnnealingLR
- OneCycleLR

## ğŸ“ è”ç³»

å¦‚æœ‰é—®é¢˜ï¼Œæ£€æŸ¥:
1. `training.log` - è®­ç»ƒæ—¥å¿—
2. `results/evaluation_results.txt` - è¯„ä¼°æŠ¥å‘Š
3. GPUä½¿ç”¨ç‡: `nvidia-smi`
