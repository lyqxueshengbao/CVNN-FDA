"""
FDA-MIMO ç»¼åˆè¯„æµ‹è„šæœ¬
å¯¹æ¯”ä¼ ç»Ÿç®—æ³• (MUSIC, ESPRIT, OMP) ä¸æ·±åº¦å­¦ä¹ æ–¹æ³• (CVNN)
"""
import os
import json
import time
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import rcParams
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
from numpy.linalg import eig, pinv, inv

import config as cfg
from model import FDA_CVNN, FDA_CVNN_Light, FDA_CVNN_Attention
from dataset import FDADataset
from utils_physics import denormalize_labels

# è®¾ç½®ä¸­æ–‡å­—ä½“
rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False


# ==================== æ¨¡å‹è·¯å¾„æŸ¥æ‰¾ ====================
def find_best_model_path(L_snapshots=None, attention_type=None):
    """
    è‡ªåŠ¨æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆæ ¹æ®å¿«æ‹æ•°å’Œæ³¨æ„åŠ›ç±»å‹ï¼‰

    å‚æ•°:
        L_snapshots: å¿«æ‹æ•°
        attention_type: æ³¨æ„åŠ›ç±»å‹ ('dual', 'se', 'far', 'standard')

    è¿”å›:
        æ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    L = L_snapshots or cfg.L_snapshots
    checkpoint_dir = cfg.checkpoint_dir
    candidates = []

    # ä¼˜å…ˆçº§1: æŒ‡å®šæ³¨æ„åŠ›ç±»å‹ + å¿«æ‹æ•°
    if attention_type and attention_type != 'standard':
        candidates.append(f"{checkpoint_dir}/fda_cvnn_{attention_type}_L{L}_best.pth")

    # ä¼˜å…ˆçº§2: ä»»æ„æ³¨æ„åŠ›ç±»å‹ + å¿«æ‹æ•°
    import glob
    pattern = f"{checkpoint_dir}/fda_cvnn_*_L{L}_best.pth"
    candidates.extend(glob.glob(pattern))

    # ä¼˜å…ˆçº§3: å¿«æ‹æ•°ï¼ˆæ— æ³¨æ„åŠ›æ ‡è¯†ï¼‰
    candidates.append(f"{checkpoint_dir}/fda_cvnn_L{L}_best.pth")

    # ä¼˜å…ˆçº§4: Lrandom é€šç”¨æ¨¡å‹
    pattern_random = f"{checkpoint_dir}/fda_cvnn_*_Lrandom_best.pth"
    candidates.extend(glob.glob(pattern_random))
    candidates.append(f"{checkpoint_dir}/fda_cvnn_Lrandom_best.pth")

    # ä¼˜å…ˆçº§5: æŒ‡å®šæ³¨æ„åŠ›ç±»å‹ï¼ˆæ— å¿«æ‹æ ‡è¯†ï¼‰
    if attention_type and attention_type != 'standard':
        candidates.append(f"{checkpoint_dir}/fda_cvnn_{attention_type}_best.pth")

    # ä¼˜å…ˆçº§6: é»˜è®¤æ¨¡å‹
    candidates.append(f"{checkpoint_dir}/fda_cvnn_best.pth")

    # è¿”å›ç¬¬ä¸€ä¸ªå­˜åœ¨çš„æ–‡ä»¶
    for path in candidates:
        if os.path.exists(path):
            return path

    # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤è·¯å¾„
    return f"{checkpoint_dir}/fda_cvnn_best.pth"


# ==================== CRLB è®¡ç®— ====================
def crlb_fda_mimo(theta_true, r_true, M, N, f0, Delta_f, c0, d, lambda_, L, SNR_dB):
    """
    è®¡ç®—FDA-MIMOçš„å…‹æ‹‰ç¾ç½—ä¸‹ç•Œ (CRLB)

    å‚æ•°:
        theta_true: çœŸå®è§’åº¦ (å¼§åº¦)
        r_true: çœŸå®è·ç¦» (ç±³)
        M, N: å‘å°„/æ¥æ”¶é˜µå…ƒæ•°
        f0: è½½é¢‘ (Hz)
        Delta_f: é¢‘ç‡åç§» (Hz)
        c0: å…‰é€Ÿ (m/s)
        d: é˜µå…ƒé—´è· (m)
        lambda_: æ³¢é•¿ (m)
        L: å¿«æ‹æ•°
        SNR_dB: ä¿¡å™ªæ¯” (dB)

    è¿”å›:
        CRLB_theta: è§’åº¦CRLB (åº¦)
        CRLB_r: è·ç¦»CRLB (ç±³)
    """
    if np.isscalar(theta_true):
        theta_true = np.array([theta_true])
        r_true = np.array([r_true])

    K = len(theta_true)
    sigma2 = 10 ** (-SNR_dB / 10)
    xi_power = 1 / sigma2

    F = np.zeros((2 * K, 2 * K))

    for i in range(K):
        # å¯¼å‘çŸ¢é‡
        tau = 2 * r_true[i] / c0
        a_t = np.exp(-1j * 2 * np.pi * np.arange(M) * Delta_f * tau)
        a_r = np.exp(1j * 2 * np.pi * d / lambda_ * np.sin(theta_true[i]) * np.arange(N))
        u = np.kron(a_t, a_r)

        # å¯¼å‘çŸ¢é‡å¯¹è§’åº¦çš„å¯¼æ•°
        d_phi_dtheta = 2 * np.pi * d / lambda_ * np.cos(theta_true[i])
        da_r_dtheta = 1j * d_phi_dtheta * np.arange(N) * a_r
        du_dtheta = np.kron(a_t, da_r_dtheta)

        # å¯¼å‘çŸ¢é‡å¯¹è·ç¦»çš„å¯¼æ•°
        d_tau_dr = 2 / c0
        da_t_dr = -1j * 2 * np.pi * Delta_f * d_tau_dr * np.arange(M) * a_t
        du_dr = np.kron(da_t_dr, a_r)

        # FIM å…ƒç´ 
        F[2 * i, 2 * i] = 2 * L * xi_power * np.real(np.dot(du_dtheta.conj(), du_dtheta))
        F[2 * i + 1, 2 * i + 1] = 2 * L * xi_power * np.real(np.dot(du_dr.conj(), du_dr))
        F[2 * i, 2 * i + 1] = 2 * L * xi_power * np.real(np.dot(du_dtheta.conj(), du_dr))
        F[2 * i + 1, 2 * i] = F[2 * i, 2 * i + 1]

    invF = inv(F)
    CRLB_theta = np.sqrt(np.diag(invF[0::2, 0::2])) * 180 / np.pi
    CRLB_r = np.sqrt(np.diag(invF[1::2, 1::2]))

    return CRLB_theta, CRLB_r


# ==================== 2D-MUSIC ç®—æ³• ====================
def music_algorithm(Y, M, N, Delta_f, c0, d, lambda_, Grid_theta, Grid_r, K):
    """
    2D-MUSIC ç®—æ³•å®ç°

    å‚æ•°:
        Y: æ¥æ”¶æ•°æ® [MN, L]
        M, N: å‘å°„/æ¥æ”¶é˜µå…ƒæ•°
        Delta_f: é¢‘ç‡åç§»
        c0: å…‰é€Ÿ
        d: é˜µå…ƒé—´è·
        lambda_: æ³¢é•¿
        Grid_theta: è§’åº¦ç½‘æ ¼ (åº¦)
        Grid_r: è·ç¦»ç½‘æ ¼ (ç±³)
        K: ç›®æ ‡æ•°

    è¿”å›:
        theta_est: è§’åº¦ä¼°è®¡ (å¼§åº¦)
        r_est: è·ç¦»ä¼°è®¡ (ç±³)
    """
    # åæ–¹å·®çŸ©é˜µ
    R = Y @ Y.conj().T / Y.shape[1]

    # ç‰¹å¾åˆ†è§£è·å–å™ªå£°å­ç©ºé—´
    D, V = eig(R)
    idx = np.argsort(np.real(D))
    Un = V[:, idx[:V.shape[1] - K]]

    # æ„å»ºäºŒç»´ç©ºé—´è°±
    P = np.zeros((len(Grid_theta), len(Grid_r)))
    for i in range(len(Grid_theta)):
        theta = Grid_theta[i] * np.pi / 180
        for j in range(len(Grid_r)):
            r = Grid_r[j]
            tau = 2 * r / c0
            a_t = np.exp(-1j * 2 * np.pi * np.arange(M) * Delta_f * tau)
            a_r = np.exp(1j * 2 * np.pi * d / lambda_ * np.sin(theta) * np.arange(N))
            a = np.kron(a_t, a_r)
            P[i, j] = 1 / np.real(a.conj().T @ Un @ Un.conj().T @ a)

    # æœç´¢è°±å³°
    peak_idx = np.argpartition(P.flatten(), -K)[-K:]
    theta_idx, r_idx = np.unravel_index(peak_idx, P.shape)
    theta_est = Grid_theta[theta_idx] * np.pi / 180
    r_est = Grid_r[r_idx]

    return theta_est, r_est


# ==================== 2D-ESPRIT ç®—æ³• ====================
def esprit_algorithm(Y, M, N, Delta_f, c0, d, lambda_, K):
    """
    2D-ESPRIT ç®—æ³•å®ç°

    å‚æ•°:
        Y: æ¥æ”¶æ•°æ® [MN, L]
        M, N: å‘å°„/æ¥æ”¶é˜µå…ƒæ•°
        Delta_f: é¢‘ç‡åç§»
        c0: å…‰é€Ÿ
        d: é˜µå…ƒé—´è·
        lambda_: æ³¢é•¿
        K: ç›®æ ‡æ•°

    è¿”å›:
        theta_est: è§’åº¦ä¼°è®¡ (å¼§åº¦)
        r_est: è·ç¦»ä¼°è®¡ (ç±³)
    """
    # åæ–¹å·®çŸ©é˜µä¸ä¿¡å·å­ç©ºé—´
    R = Y @ Y.conj().T / Y.shape[1]
    D, V = eig(R)
    idx = np.argsort(np.real(D))[::-1]
    Es = V[:, idx[:K]]

    # é€‰æ‹©çŸ©é˜µ
    JR1 = np.kron(np.eye(M), np.hstack([np.eye(N - 1), np.zeros((N - 1, 1))]))
    JR2 = np.kron(np.eye(M), np.hstack([np.zeros((N - 1, 1)), np.eye(N - 1)]))
    JT1 = np.kron(np.hstack([np.eye(M - 1), np.zeros((M - 1, 1))]), np.eye(N))
    JT2 = np.kron(np.hstack([np.zeros((M - 1, 1)), np.eye(M - 1)]), np.eye(N))

    # è§’åº¦ä¼°è®¡
    T_theta = JR2 @ Es
    S_theta = JR1 @ Es
    Psi_theta = pinv(S_theta) @ T_theta
    D_theta, V_theta = eig(Psi_theta)
    phi_theta = D_theta
    theta_est = np.arcsin(np.angle(phi_theta) * lambda_ / (2 * np.pi * d))

    # è·ç¦»ä¼°è®¡
    T_r = JT2 @ Es
    S_r = JT1 @ Es
    Psi_r = pinv(S_r) @ T_r
    D_r, V_r = eig(Psi_r)
    phi_r = D_r
    r_est = -(np.angle(phi_r) * c0) / (4 * np.pi * Delta_f)

    # å‚æ•°é…å¯¹
    match_idx = np.argmax(np.abs(V_theta.conj().T @ V_r), axis=1)
    r_est = r_est[match_idx]

    return theta_est, r_est


# ==================== OMP ç®—æ³• ====================
def omp_algorithm(Y, M, N, Delta_f, c0, d, lambda_, Grid_theta, Grid_r, K):
    """
    OMP (æ­£äº¤åŒ¹é…è¿½è¸ª) ç®—æ³•å®ç°

    å‚æ•°:
        Y: æ¥æ”¶æ•°æ® [MN, L]
        M, N: å‘å°„/æ¥æ”¶é˜µå…ƒæ•°
        Delta_f: é¢‘ç‡åç§»
        c0: å…‰é€Ÿ
        d: é˜µå…ƒé—´è·
        lambda_: æ³¢é•¿
        Grid_theta: è§’åº¦ç½‘æ ¼ (åº¦)
        Grid_r: è·ç¦»ç½‘æ ¼ (ç±³)
        K: ç›®æ ‡æ•°

    è¿”å›:
        theta_est: è§’åº¦ä¼°è®¡ (å¼§åº¦)
        r_est: è·ç¦»ä¼°è®¡ (ç±³)
    """
    X = Y[:, 0]  # å•å¿«æ‹

    # æ„å»ºè¿‡å®Œå¤‡å­—å…¸
    A = []
    for i in range(len(Grid_theta)):
        theta = Grid_theta[i] * np.pi / 180
        for j in range(len(Grid_r)):
            r = Grid_r[j]
            tau = 2 * r / c0
            a_t = np.exp(-1j * 2 * np.pi * np.arange(M) * Delta_f * tau)
            a_r = np.exp(1j * 2 * np.pi * d / lambda_ * np.sin(theta) * np.arange(N))
            a = np.kron(a_t, a_r)
            A.append(a)
    A = np.array(A).T

    # åˆ—å½’ä¸€åŒ–
    A = A / np.sqrt(np.sum(np.abs(A) ** 2, axis=0))

    # OMP è¿­ä»£
    r = X.copy()
    Lambda = []
    for iter in range(K):
        corr = np.abs(np.dot(A.conj().T, r))
        idx = np.argmax(corr)
        Lambda.append(idx)

        A_sub = A[:, Lambda]
        s_hat = pinv(A_sub) @ X
        X_hat = A_sub @ s_hat
        r = X - X_hat

    # æå–å‚æ•°
    r_idx = np.array(Lambda) % len(Grid_r)
    theta_idx = np.array(Lambda) // len(Grid_r)
    theta_est = Grid_theta[theta_idx] * np.pi / 180
    r_est = Grid_r[r_idx]

    return theta_est, r_est


# ==================== ä¼ ç»Ÿç®—æ³•è¯„æµ‹ ====================
def evaluate_classical_algorithm(algorithm_name, algorithm_func, params,
                                  SNR_dB_list, Monte_Carlo=100):
    """
    è¯„æµ‹ä¼ ç»Ÿç®—æ³•åœ¨å¤šä¸ªSNRä¸‹çš„æ€§èƒ½

    å‚æ•°:
        algorithm_name: ç®—æ³•åç§°
        algorithm_func: ç®—æ³•å‡½æ•°
        params: ç®—æ³•å‚æ•°å­—å…¸
        SNR_dB_list: SNRåˆ—è¡¨
        Monte_Carlo: è’™ç‰¹å¡æ´›æ¬¡æ•°

    è¿”å›:
        results: è¯„æµ‹ç»“æœå­—å…¸
    """
    M = params['M']
    N = params['N']
    Delta_f = params['Delta_f']
    c0 = params['c0']
    d = params['d']
    lambda_ = params['lambda_']
    K = params['K']
    L = params['L']
    theta_true = params['theta_true']
    r_true = params['r_true']
    Grid_theta = params.get('Grid_theta', None)
    Grid_r = params.get('Grid_r', None)

    rmse_theta_list = []
    rmse_r_list = []
    time_list = []

    print(f"\nè¯„æµ‹ {algorithm_name} ç®—æ³•...")

    for snr_idx, SNR in enumerate(tqdm(SNR_dB_list, desc=algorithm_name)):
        sigma2 = 10 ** (-SNR / 10)

        theta_err_total = 0
        r_err_total = 0
        time_total = 0

        for mc in range(Monte_Carlo):
            # ç”Ÿæˆæ¥æ”¶æ•°æ®
            Y = np.zeros((M * N, L), dtype=complex)
            for k in range(K):
                theta = theta_true if K == 1 else theta_true[k]
                r = r_true if K == 1 else r_true[k]
                tau = 2 * r / c0
                a_t = np.exp(-1j * 2 * np.pi * np.arange(M) * Delta_f * tau)
                a_r = np.exp(1j * 2 * np.pi * d / lambda_ * np.sin(theta) * np.arange(N))
                a = np.kron(a_t, a_r)
                s = np.sqrt(1 / sigma2) * (np.random.randn(1, L) + 1j * np.random.randn(1, L))
                Y = Y + np.outer(a, s)
            Y = Y + np.sqrt(sigma2 / 2) * (np.random.randn(M * N, L) + 1j * np.random.randn(M * N, L))

            # è¿è¡Œç®—æ³•
            start_time = time.time()
            if algorithm_name in ['2D-MUSIC', 'OMP']:
                theta_est, r_est = algorithm_func(Y, M, N, Delta_f, c0, d, lambda_,
                                                  Grid_theta, Grid_r, K)
            else:  # ESPRIT
                theta_est, r_est = algorithm_func(Y, M, N, Delta_f, c0, d, lambda_, K)
            time_total += time.time() - start_time

            # è®¡ç®—è¯¯å·®
            for k in range(K):
                theta_k = theta_true if K == 1 else theta_true[k]
                match_theta = np.argmin(np.abs(theta_est - theta_k))
                theta_err = (theta_est[match_theta] - theta_k) ** 2
                theta_err_total += theta_err

                r_k = r_true if K == 1 else r_true[k]
                match_r = np.argmin(np.abs(r_est - r_k))
                r_err = (r_est[match_r] - r_k) ** 2
                r_err_total += r_err

        # è®¡ç®— RMSE
        rmse_theta = np.sqrt(theta_err_total / (Monte_Carlo * K)) * 180 / np.pi
        rmse_r = np.sqrt(r_err_total / (Monte_Carlo * K))
        avg_time = time_total / Monte_Carlo

        rmse_theta_list.append(rmse_theta)
        rmse_r_list.append(rmse_r)
        time_list.append(avg_time)

    results = {
        'algorithm': algorithm_name,
        'snr_db_list': SNR_dB_list.tolist(),
        'rmse_theta': rmse_theta_list,
        'rmse_r': rmse_r_list,
        'avg_time': time_list
    }

    return results


# ==================== CVNN è¯„æµ‹ ====================
def evaluate_cvnn(model_path, SNR_dB_list, num_samples=1000, batch_size=64,
                  device='cuda', attention_type='dual', reduction=8, auto_detect=False,
                  L_snapshots=None):
    """
    è¯„æµ‹ CVNN æ¨¡å‹åœ¨å¤šä¸ªSNRä¸‹çš„æ€§èƒ½

    å‚æ•°:
        model_path: æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneæˆ–é»˜è®¤è·¯å¾„ï¼Œä¼šè‡ªåŠ¨æŸ¥æ‰¾ï¼‰
        SNR_dB_list: SNRåˆ—è¡¨
        num_samples: æ¯ä¸ªSNRçš„æµ‹è¯•æ ·æœ¬æ•°
        batch_size: æ‰¹æ¬¡å¤§å°
        device: è®¾å¤‡
        attention_type: æ³¨æ„åŠ›ç±»å‹ ('dual', 'se', 'far', 'standard')
        reduction: æ³¨æ„åŠ›æ¨¡å—çš„å‹ç¼©æ¯” (4, 8, 16ç­‰)
        auto_detect: æ˜¯å¦è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆé»˜è®¤Falseï¼Œä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šï¼‰
        L_snapshots: å¿«æ‹æ•°ï¼ˆç”¨äºæŸ¥æ‰¾å¯¹åº”çš„æ¨¡å‹æ–‡ä»¶ï¼‰

    è¿”å›:
        results: è¯„æµ‹ç»“æœå­—å…¸
    """
    # å¦‚æœæ˜¯é»˜è®¤è·¯å¾„æˆ–Noneï¼Œè‡ªåŠ¨æŸ¥æ‰¾æœ€ä½³æ¨¡å‹
    if model_path is None or model_path == cfg.model_save_path:
        model_path = find_best_model_path(L_snapshots, attention_type)
        print(f"ğŸ” è‡ªåŠ¨é€‰æ‹©æ¨¡å‹: {model_path}")

    if model_path and os.path.exists(model_path):
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint

        if auto_detect:
            # è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆå¯èƒ½ä¸å‡†ç¡®ï¼‰
            keys = list(state_dict.keys())
            has_dual = any('global_attn' in k or 'local_attn' in k for k in keys)
            has_far = any('attn' in k and 'conv_rr' in k for k in keys) and not has_dual
            has_se = any('attn' in k and '.fc.' in k for k in keys) and not has_dual

            if has_dual:
                attention_type = 'dual'
            elif has_far:
                attention_type = 'far'
            elif has_se:
                attention_type = 'se'
            else:
                attention_type = 'standard'

            # å°è¯•ä»æƒé‡å½¢çŠ¶æ¨æ–­reduction
            for key in keys:
                if 'attn1.fc.0.weight' in key or 'attn1.global_attn.fc.0.weight' in key:
                    weight_shape = state_dict[key].shape
                    reduction = 32 // weight_shape[0]  # 32æ˜¯é€šé“æ•°
                    break

        # è‡ªåŠ¨ä»æƒé‡æ¨æ–­ reductionï¼ˆå¦‚æœæœªå¯ç”¨ auto_detectï¼‰
        if not auto_detect and attention_type != 'standard':
            keys = list(state_dict.keys())
            for key in keys:
                # æ£€æŸ¥ç¬¬ä¸€å±‚æ³¨æ„åŠ›çš„æƒé‡
                if 'attn1.global_attn.fc.0.weight' in key:  # Dual
                    weight_shape = state_dict[key].shape
                    inferred_reduction = 32 // weight_shape[0]
                    if inferred_reduction != reduction:
                        print(f"âš  æ£€æµ‹åˆ° reduction ä¸åŒ¹é…ï¼")
                        print(f"  æŒ‡å®šå€¼: {reduction}, ä»æƒé‡æ¨æ–­: {inferred_reduction}")
                        print(f"  ä½¿ç”¨æ¨æ–­å€¼: {inferred_reduction}")
                        reduction = inferred_reduction
                    break
                elif 'attn1.fc.0.weight' in key:  # SE/FAR
                    weight_shape = state_dict[key].shape
                    inferred_reduction = 32 // weight_shape[0]
                    if inferred_reduction != reduction:
                        print(f"âš  æ£€æµ‹åˆ° reduction ä¸åŒ¹é…ï¼")
                        print(f"  æŒ‡å®šå€¼: {reduction}, ä»æƒé‡æ¨æ–­: {inferred_reduction}")
                        print(f"  ä½¿ç”¨æ¨æ–­å€¼: {inferred_reduction}")
                        reduction = inferred_reduction
                    break

        # æ ¹æ®æŒ‡å®šçš„å‚æ•°å®ä¾‹åŒ–æ¨¡å‹
        if attention_type == 'dual':
            model = FDA_CVNN_Attention(attention_type='dual', se_reduction=reduction).to(device)
            print(f"âœ“ ä½¿ç”¨æ¨¡å‹: FDA_CVNN_Attention(dual, reduction={reduction})")
        elif attention_type == 'far':
            model = FDA_CVNN_Attention(attention_type='far', se_reduction=reduction).to(device)
            print(f"âœ“ ä½¿ç”¨æ¨¡å‹: FDA_CVNN_Attention(far, reduction={reduction})")
        elif attention_type == 'se':
            model = FDA_CVNN_Attention(attention_type='se', se_reduction=reduction).to(device)
            print(f"âœ“ ä½¿ç”¨æ¨¡å‹: FDA_CVNN_Attention(se, reduction={reduction})")
        else:
            model = FDA_CVNN().to(device)
            print(f"âœ“ ä½¿ç”¨æ¨¡å‹: FDA_CVNN(standard)")

        # ç§»é™¤ module. å‰ç¼€ï¼ˆå¤šGPUè®­ç»ƒçš„äº§ç‰©ï¼‰
        new_state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict, strict=False)
        print(f"âœ“ å·²åŠ è½½æ¨¡å‹: {model_path}")
    else:
        print(f"âš  è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
        model = FDA_CVNN().to(device)

    model.eval()

    rmse_theta_list = []
    rmse_r_list = []
    time_list = []

    print(f"\nè¯„æµ‹ CVNN æ¨¡å‹...")

    for SNR in tqdm(SNR_dB_list, desc="CVNN"):
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
        seed = abs(int(cfg.seed + SNR * 100)) % (2**31)
        dataset = FDADataset(num_samples, snr_db=SNR, online=False, seed=seed)
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

        all_preds = []
        all_labels = []
        time_total = 0

        with torch.no_grad():
            for batch_x, batch_y in loader:
                batch_x = batch_x.to(device)
                start_time = time.time()
                preds = model(batch_x)
                time_total += time.time() - start_time
                all_preds.append(preds.cpu())
                all_labels.append(batch_y)

        all_preds = torch.cat(all_preds, dim=0).numpy()
        all_labels = torch.cat(all_labels, dim=0).numpy()

        # åå½’ä¸€åŒ–
        preds_physical = denormalize_labels(all_preds)
        labels_physical = denormalize_labels(all_labels)

        # è®¡ç®—è¯¯å·®
        r_error = preds_physical[:, 0] - labels_physical[:, 0]
        theta_error = preds_physical[:, 1] - labels_physical[:, 1]

        rmse_r = float(np.sqrt(np.mean(r_error ** 2)))
        rmse_theta = float(np.sqrt(np.mean(theta_error ** 2)))
        avg_time = time_total / num_samples

        rmse_theta_list.append(rmse_theta)
        rmse_r_list.append(rmse_r)
        time_list.append(avg_time)

    results = {
        'algorithm': 'CVNN',
        'snr_db_list': SNR_dB_list.tolist(),
        'rmse_theta': rmse_theta_list,
        'rmse_r': rmse_r_list,
        'avg_time': time_list
    }

    return results


# ==================== ç»˜å›¾å‡½æ•° ====================
def plot_comparison(all_results, crlb_results, save_path='results'):
    """
    ç»˜åˆ¶æ‰€æœ‰ç®—æ³•çš„å¯¹æ¯”å›¾

    å‚æ•°:
        all_results: æ‰€æœ‰ç®—æ³•çš„ç»“æœåˆ—è¡¨
        crlb_results: CRLBç»“æœ
        save_path: ä¿å­˜è·¯å¾„
    """
    os.makedirs(save_path, exist_ok=True)

    # é¢œè‰²å’Œæ ‡è®°
    colors = ['b', 'g', 'r', 'm', 'c']
    markers = ['o', 's', '^', 'd', 'v']

    # è§’åº¦ RMSE
    plt.figure(figsize=(10, 6))
    for idx, result in enumerate(all_results):
        snr_list = result['snr_db_list']
        rmse_theta = result['rmse_theta']
        label = result['algorithm']
        plt.semilogy(snr_list, rmse_theta,
                    color=colors[idx % len(colors)],
                    marker=markers[idx % len(markers)],
                    linewidth=2, markersize=8, label=label)

    # ç»˜åˆ¶ CRLB
    plt.semilogy(crlb_results['snr_db_list'], crlb_results['crlb_theta'],
                'k--', linewidth=2, label='CRLB')

    plt.xlabel('SNR (dB)', fontsize=14)
    plt.ylabel('Angle RMSE (deg)', fontsize=14)
    plt.title('Angle Estimation Performance Comparison', fontsize=16)
    plt.grid(True, which='both', alpha=0.3)
    plt.legend(fontsize=12)
    plt.tight_layout()
    plt.savefig(f'{save_path}/angle_comparison.png', dpi=300)
    plt.savefig(f'{save_path}/angle_comparison.pdf')
    print(f"å·²ä¿å­˜è§’åº¦å¯¹æ¯”å›¾: {save_path}/angle_comparison.png")

    # è·ç¦» RMSE
    plt.figure(figsize=(10, 6))
    for idx, result in enumerate(all_results):
        snr_list = result['snr_db_list']
        rmse_r = result['rmse_r']
        label = result['algorithm']
        plt.semilogy(snr_list, rmse_r,
                    color=colors[idx % len(colors)],
                    marker=markers[idx % len(markers)],
                    linewidth=2, markersize=8, label=label)

    # ç»˜åˆ¶ CRLB
    plt.semilogy(crlb_results['snr_db_list'], crlb_results['crlb_r'],
                'k--', linewidth=2, label='CRLB')

    plt.xlabel('SNR (dB)', fontsize=14)
    plt.ylabel('Range RMSE (m)', fontsize=14)
    plt.title('Range Estimation Performance Comparison', fontsize=16)
    plt.grid(True, which='both', alpha=0.3)
    plt.legend(fontsize=12)
    plt.tight_layout()
    plt.savefig(f'{save_path}/range_comparison.png', dpi=300)
    plt.savefig(f'{save_path}/range_comparison.pdf')
    print(f"å·²ä¿å­˜è·ç¦»å¯¹æ¯”å›¾: {save_path}/range_comparison.png")

    # è®¡ç®—æ—¶é—´å¯¹æ¯”ï¼ˆæŸ±çŠ¶å›¾ï¼‰
    plt.figure(figsize=(10, 6))
    algorithms = [r['algorithm'] for r in all_results]
    avg_times = [np.mean(r['avg_time']) * 1000 for r in all_results]  # è½¬ä¸ºæ¯«ç§’

    bars = plt.bar(algorithms, avg_times, color=colors[:len(algorithms)], alpha=0.7, edgecolor='black')
    plt.ylabel('Average Time (ms)', fontsize=14)
    plt.title('Computational Time Comparison (Average)', fontsize=16)
    plt.yscale('log')
    plt.grid(True, axis='y', alpha=0.3)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, time_val in zip(bars, avg_times):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{time_val:.2f}',
                ha='center', va='bottom', fontsize=10)

    plt.tight_layout()
    plt.savefig(f'{save_path}/time_comparison_bar.png', dpi=300)
    plt.savefig(f'{save_path}/time_comparison_bar.pdf')
    print(f"å·²ä¿å­˜æ—¶é—´å¯¹æ¯”æŸ±çŠ¶å›¾: {save_path}/time_comparison_bar.png")

    # è®¡ç®—æ—¶é—´éšSNRå˜åŒ–ï¼ˆæ›²çº¿å›¾ï¼‰
    plt.figure(figsize=(10, 6))
    for idx, result in enumerate(all_results):
        snr_list = result['snr_db_list']
        time_list = [t * 1000 for t in result['avg_time']]  # è½¬ä¸ºæ¯«ç§’
        label = result['algorithm']
        plt.semilogy(snr_list, time_list,
                    color=colors[idx % len(colors)],
                    marker=markers[idx % len(markers)],
                    linewidth=2, markersize=8, label=label)

    plt.xlabel('SNR (dB)', fontsize=14)
    plt.ylabel('Computational Time (ms)', fontsize=14)
    plt.title('Computational Time vs SNR', fontsize=16)
    plt.grid(True, which='both', alpha=0.3)
    plt.legend(fontsize=12)
    plt.tight_layout()
    plt.savefig(f'{save_path}/time_vs_snr.png', dpi=300)
    plt.savefig(f'{save_path}/time_vs_snr.pdf')
    print(f"å·²ä¿å­˜æ—¶é—´éšSNRå˜åŒ–å›¾: {save_path}/time_vs_snr.png")

    print("=" * 60)


# ==================== æ¥å£å‡½æ•°ï¼ˆä¾› main.py è°ƒç”¨ï¼‰ ====================
def run_comprehensive_benchmark(L_snapshots=None, num_samples_cvnn=1000,
                                monte_carlo_classical=100,
                                attention_type='dual', reduction=8):
    """
    è¿è¡Œç»¼åˆå¯¹æ¯”å®éªŒçš„æ¥å£å‡½æ•°

    å‚æ•°:
        L_snapshots: å¿«æ‹æ•°ï¼ˆNoneè¡¨ç¤ºä½¿ç”¨configé»˜è®¤å€¼ï¼‰
        num_samples_cvnn: CVNNæµ‹è¯•æ ·æœ¬æ•°
        monte_carlo_classical: ä¼ ç»Ÿç®—æ³•è’™ç‰¹å¡æ´›æ¬¡æ•°
        attention_type: CVNNæ³¨æ„åŠ›ç±»å‹
        reduction: CVNNå‹ç¼©æ¯”
    """
    # ========== å‚æ•°è®¾ç½® ==========
    M = cfg.M
    N = cfg.N
    f0 = cfg.f0
    Delta_f = cfg.delta_f
    c0 = cfg.c
    lambda_ = cfg.wavelength
    d = cfg.d
    K = 1
    theta_true = 10.0 * np.pi / 180
    r_true = 2000.0
    L = L_snapshots if L_snapshots else cfg.L_snapshots

    SNR_dB_list = np.arange(-15, 25, 5)

    Grid_theta = np.arange(-50, 51, 1)
    Grid_r = np.arange(0, 5001, 100)

    model_path = cfg.model_save_path

    save_path = 'results/comprehensive_benchmark'
    os.makedirs(save_path, exist_ok=True)

    # ========== è®¡ç®— CRLB ==========
    print("\n" + "=" * 60)
    print("è®¡ç®— CRLB...")
    print("=" * 60)

    crlb_theta_list = []
    crlb_r_list = []

    for SNR in SNR_dB_list:
        crlb_theta, crlb_r = crlb_fda_mimo(
            theta_true, r_true, M, N, f0, Delta_f, c0, d, lambda_, L, SNR
        )
        crlb_theta_list.append(crlb_theta[0])
        crlb_r_list.append(crlb_r[0])

    crlb_results = {
        'snr_db_list': SNR_dB_list.tolist(),
        'crlb_theta': crlb_theta_list,
        'crlb_r': crlb_r_list
    }

    # ========== è¯„æµ‹ CVNNï¼ˆä¼˜å…ˆè¯„æµ‹ï¼Œå¿«é€ŸéªŒè¯æ¨¡å‹åŠ è½½ï¼‰ ==========
    print("\n" + "=" * 60)
    print("è¯„æµ‹ CVNN æ¨¡å‹...")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    cvnn_results = evaluate_cvnn(
        model_path, SNR_dB_list, num_samples_cvnn,
        batch_size=64, device=device,
        attention_type=attention_type,
        reduction=reduction,
        auto_detect=False,
        L_snapshots=L  # ä¼ é€’å¿«æ‹æ•°ï¼Œç”¨äºæŸ¥æ‰¾å¯¹åº”æ¨¡å‹
    )

    # ========== è¯„æµ‹ä¼ ç»Ÿç®—æ³• ==========
    print("\n" + "=" * 60)
    print("è¯„æµ‹ä¼ ç»Ÿç®—æ³•...")
    print("=" * 60)

    params = {
        'M': M, 'N': N, 'Delta_f': Delta_f, 'c0': c0, 'd': d, 'lambda_': lambda_,
        'K': K, 'L': L, 'theta_true': theta_true, 'r_true': r_true,
        'Grid_theta': Grid_theta, 'Grid_r': Grid_r
    }

    classical_results = []

    # 2D-MUSIC
    music_results = evaluate_classical_algorithm(
        '2D-MUSIC', music_algorithm, params, SNR_dB_list, monte_carlo_classical
    )
    classical_results.append(music_results)

    # 2D-ESPRIT
    esprit_results = evaluate_classical_algorithm(
        '2D-ESPRIT', esprit_algorithm, params, SNR_dB_list, monte_carlo_classical
    )
    classical_results.append(esprit_results)

    # OMP
    omp_results = evaluate_classical_algorithm(
        'OMP', omp_algorithm, params, SNR_dB_list, monte_carlo_classical
    )
    classical_results.append(omp_results)

    # ========== åˆå¹¶ç»“æœ ==========
    all_results = [cvnn_results] + classical_results

    # ========== ä¿å­˜ç»“æœ ==========
    print("\n" + "=" * 60)
    print("ä¿å­˜ç»“æœ...")
    print("=" * 60)

    results_dict = {
        'crlb': crlb_results,
        'algorithms': all_results,
        'parameters': {
            'M': M, 'N': N, 'f0': f0, 'Delta_f': Delta_f,
            'theta_true_deg': theta_true * 180 / np.pi,
            'r_true_m': r_true,
            'L': L,
            'Monte_Carlo_classical': monte_carlo_classical,
            'num_samples_cvnn': num_samples_cvnn,
            'attention_type': attention_type,
            'reduction': reduction
        }
    }

    with open(f'{save_path}/benchmark_results.json', 'w', encoding='utf-8') as f:
        json.dump(results_dict, f, indent=2, ensure_ascii=False)
    print(f"å·²ä¿å­˜ç»“æœ: {save_path}/benchmark_results.json")

    # ========== ç»˜åˆ¶å¯¹æ¯”å›¾ ==========
    print("\n" + "=" * 60)
    print("ç»˜åˆ¶å¯¹æ¯”å›¾...")
    print("=" * 60)

    plot_comparison(all_results, crlb_results, save_path)

    # ========== æ‰“å°æ€§èƒ½æ€»ç»“ ==========
    print("\n" + "=" * 60)
    print("æ€§èƒ½æ€»ç»“ (SNR = 20dB)")
    print("=" * 60)
    print(f"{'Algorithm':<15} {'Angle RMSE (deg)':<20} {'Range RMSE (m)':<20} {'Time (ms)':<15}")
    print("-" * 70)

    snr_20_idx = np.where(SNR_dB_list == 20)[0]
    if len(snr_20_idx) > 0:
        idx = snr_20_idx[0]
        for result in all_results:
            algo = result['algorithm']
            angle_rmse = result['rmse_theta'][idx]
            range_rmse = result['rmse_r'][idx]
            avg_time = result['avg_time'][idx] * 1000
            print(f"{algo:<15} {angle_rmse:<20.4f} {range_rmse:<20.4f} {avg_time:<15.4f}")

        crlb_angle = crlb_results['crlb_theta'][idx]
        crlb_range = crlb_results['crlb_r'][idx]
        print("-" * 70)
        print(f"{'CRLB':<15} {crlb_angle:<20.4f} {crlb_range:<20.4f} {'-':<15}")

    print("\n" + "=" * 60)
    print("è¯„æµ‹å®Œæˆï¼")
    print("=" * 60)


# ==================== ä¸»å‡½æ•° ====================
def main():
    # ========== CVNN æ¨¡å‹é…ç½®ï¼ˆæ ¹æ®å®é™…è®­ç»ƒå‚æ•°ä¿®æ”¹ï¼‰ ==========
    CVNN_ATTENTION_TYPE = 'dual'  # æ¨¡å‹æ³¨æ„åŠ›ç±»å‹: 'dual', 'se', 'far', 'standard'
    CVNN_REDUCTION = 8            # æ³¨æ„åŠ›æ¨¡å—å‹ç¼©æ¯”: 4, 8, 16ç­‰
    CVNN_AUTO_DETECT = False      # æ˜¯å¦è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆæ¨èFalseï¼Œæ‰‹åŠ¨æŒ‡å®šæ›´å‡†ç¡®ï¼‰

    # ========== ç‰©ç†å‚æ•° (ä¸ config.py ä¿æŒä¸€è‡´) ==========
    M = cfg.M
    N = cfg.N
    f0 = cfg.f0
    Delta_f = cfg.delta_f
    c0 = cfg.c
    lambda_ = cfg.wavelength
    d = cfg.d
    K = 1
    theta_true = 10.0 * np.pi / 180  # 10åº¦
    r_true = 2000.0  # 2000ç±³
    L = 1  # å¿«æ‹æ•°ï¼ˆå•å¿«æ‹åœºæ™¯ï¼‰

    # SNR èŒƒå›´
    SNR_dB_list = np.arange(-15, 25, 5)

    # è’™ç‰¹å¡æ´›å‚æ•°
    Monte_Carlo_classical = 100  # ä¼ ç»Ÿç®—æ³•çš„è’™ç‰¹å¡æ´›æ¬¡æ•°
    num_samples_cvnn = 1000      # CVNN çš„æµ‹è¯•æ ·æœ¬æ•°

    # ç½‘æ ¼å‚æ•° (ç”¨äº MUSIC å’Œ OMP)
    Grid_theta = np.arange(-50, 51, 1)  # -50Â° åˆ° 50Â°ï¼Œæ­¥é•¿ 1Â°
    Grid_r = np.arange(0, 5001, 100)    # 0m åˆ° 5000mï¼Œæ­¥é•¿ 100m

    # CVNN æ¨¡å‹è·¯å¾„
    model_path = cfg.model_save_path

    # ç»“æœä¿å­˜è·¯å¾„
    save_path = 'results/comprehensive_benchmark'
    os.makedirs(save_path, exist_ok=True)

    # ========== è®¡ç®— CRLB ==========
    print("\n" + "=" * 60)
    print("è®¡ç®— CRLB...")
    print("=" * 60)

    crlb_theta_list = []
    crlb_r_list = []

    for SNR in SNR_dB_list:
        crlb_theta, crlb_r = crlb_fda_mimo(
            theta_true, r_true, M, N, f0, Delta_f, c0, d, lambda_, L, SNR
        )
        crlb_theta_list.append(crlb_theta[0])
        crlb_r_list.append(crlb_r[0])

    crlb_results = {
        'snr_db_list': SNR_dB_list.tolist(),
        'crlb_theta': crlb_theta_list,
        'crlb_r': crlb_r_list
    }

    # ========== è¯„æµ‹ CVNNï¼ˆä¼˜å…ˆè¯„æµ‹ï¼Œå¿«é€ŸéªŒè¯æ¨¡å‹åŠ è½½ï¼‰ ==========
    print("\n" + "=" * 60)
    print("è¯„æµ‹ CVNN æ¨¡å‹...")
    print("=" * 60)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹é…ç½®ï¼ˆæœåŠ¡å™¨ä¸Šè¿è¡Œæ—¶ç¡®ä¿æ­£ç¡®ï¼‰
    cvnn_results = evaluate_cvnn(
        model_path, SNR_dB_list, num_samples_cvnn,
        batch_size=64, device=device,
        attention_type=CVNN_ATTENTION_TYPE,
        reduction=CVNN_REDUCTION,
        auto_detect=CVNN_AUTO_DETECT,
        L_snapshots=L  # ä¼ é€’å¿«æ‹æ•°ï¼Œç”¨äºæŸ¥æ‰¾å¯¹åº”æ¨¡å‹
    )

    # ========== è¯„æµ‹ä¼ ç»Ÿç®—æ³• ==========
    print("\n" + "=" * 60)
    print("è¯„æµ‹ä¼ ç»Ÿç®—æ³•...")
    print("=" * 60)

    params = {
        'M': M, 'N': N, 'Delta_f': Delta_f, 'c0': c0, 'd': d, 'lambda_': lambda_,
        'K': K, 'L': L, 'theta_true': theta_true, 'r_true': r_true,
        'Grid_theta': Grid_theta, 'Grid_r': Grid_r
    }

    classical_results = []

    # 2D-MUSIC
    music_results = evaluate_classical_algorithm(
        '2D-MUSIC', music_algorithm, params, SNR_dB_list, Monte_Carlo_classical
    )
    classical_results.append(music_results)

    # 2D-ESPRIT
    esprit_results = evaluate_classical_algorithm(
        '2D-ESPRIT', esprit_algorithm, params, SNR_dB_list, Monte_Carlo_classical
    )
    classical_results.append(esprit_results)

    # OMP
    omp_results = evaluate_classical_algorithm(
        'OMP', omp_algorithm, params, SNR_dB_list, Monte_Carlo_classical
    )
    classical_results.append(omp_results)

    # ========== åˆå¹¶ç»“æœ ==========
    all_results = [cvnn_results] + classical_results

    # ========== ä¿å­˜ç»“æœ ==========
    print("\n" + "=" * 60)
    print("ä¿å­˜ç»“æœ...")
    print("=" * 60)

    results_dict = {
        'crlb': crlb_results,
        'algorithms': all_results,
        'parameters': {
            'M': M, 'N': N, 'f0': f0, 'Delta_f': Delta_f,
            'theta_true_deg': theta_true * 180 / np.pi,
            'r_true_m': r_true,
            'L': L,
            'Monte_Carlo_classical': Monte_Carlo_classical,
            'num_samples_cvnn': num_samples_cvnn
        }
    }

    with open(f'{save_path}/benchmark_results.json', 'w', encoding='utf-8') as f:
        json.dump(results_dict, f, indent=2, ensure_ascii=False)
    print(f"å·²ä¿å­˜ç»“æœ: {save_path}/benchmark_results.json")

    # ========== ç»˜åˆ¶å¯¹æ¯”å›¾ ==========
    print("\n" + "=" * 60)
    print("ç»˜åˆ¶å¯¹æ¯”å›¾...")
    print("=" * 60)

    plot_comparison(all_results, crlb_results, save_path)

    # ========== æ‰“å°æ€§èƒ½æ€»ç»“ ==========
    print("\n" + "=" * 60)
    print("æ€§èƒ½æ€»ç»“ (SNR = 20dB)")
    print("=" * 60)
    print(f"{'Algorithm':<15} {'Angle RMSE (deg)':<20} {'Range RMSE (m)':<20} {'Time (ms)':<15}")
    print("-" * 70)

    snr_20_idx = np.where(SNR_dB_list == 20)[0]
    if len(snr_20_idx) > 0:
        idx = snr_20_idx[0]
        for result in all_results:
            algo = result['algorithm']
            angle_rmse = result['rmse_theta'][idx]
            range_rmse = result['rmse_r'][idx]
            avg_time = result['avg_time'][idx] * 1000
            print(f"{algo:<15} {angle_rmse:<20.4f} {range_rmse:<20.4f} {avg_time:<15.4f}")

        # CRLB
        crlb_angle = crlb_results['crlb_theta'][idx]
        crlb_range = crlb_results['crlb_r'][idx]
        print("-" * 70)
        print(f"{'CRLB':<15} {crlb_angle:<20.4f} {crlb_range:<20.4f} {'-':<15}")

    print("\n" + "=" * 60)
    print("è¯„æµ‹å®Œæˆï¼")
    print("=" * 60)


if __name__ == '__main__':
    main()
